# main.py

import logging
import html
import io
import os
import asyncio
import zipfile
import shutil
import aiohttp
import yt_dlp
import httpx
import numpy as np
from datetime import datetime

from aiohttp import web
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command, StateFilter, CommandObject
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import BufferedInputFile, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove, FSInputFile

from config import TELEGRAM_BOT_TOKEN
from youtube_analyzer import YouTubeAnalyzer
from trends_analyzer import analyze_google_trends
from excel_generator import ExcelGenerator
from channel_graphics import create_activity_graphs, create_heatmap_graph

logging.basicConfig(level=logging.INFO)

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
youtube_analyzer = YouTubeAnalyzer()


# --- –°–û–°–¢–û–Ø–ù–ò–Ø ---
class UserStates(StatesGroup):
    waiting_for_video_link = State()
    waiting_for_channel_link = State()
    waiting_for_trends_query = State()
    waiting_for_niche_name = State()
    niche_analysis = State()
    waiting_for_all_titles_link = State()
    waiting_for_thumb_count = State()
    waiting_for_thumb_channel = State()


# --- –ö–õ–ê–í–ò–ê–¢–£–†–´ ---
def get_main_keyboard():
    buttons = [
        [types.InlineKeyboardButton(text="üé• –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –≤–∏–¥–µ–æ", callback_data="analyze_video")],
        [types.InlineKeyboardButton(text="üîó –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–∞", callback_data="analyze_channel")],
        [types.InlineKeyboardButton(text="üìë –í—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ", callback_data="get_all_titles")],
        [
            types.InlineKeyboardButton(text="üìà Google Trends", callback_data="cmd_trends"),
            types.InlineKeyboardButton(text="üìä –ê–Ω–∞–ª–∏–∑ –Ω–∏—à–∏ (Excel)", callback_data="cmd_excel")
        ]
    ]
    keyboard = types.InlineKeyboardMarkup(inline_keyboard=buttons)
    return keyboard


def get_niche_analysis_keyboard():
    buttons = [
        [KeyboardButton(text="üíæ –ì–æ—Ç–æ–≤–æ –∏ –°–∫–∞—á–∞—Ç—å")]
    ]
    keyboard = ReplyKeyboardMarkup(keyboard=buttons, resize_keyboard=True, one_time_keyboard=False)
    return keyboard


# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def pluralize_canal(count: int) -> str:
    if count % 10 == 1 and count % 100 != 11:
        return "–∫–∞–Ω–∞–ª"
    elif 2 <= count % 10 <= 4 and (count % 100 < 10 or count % 100 >= 20):
        return "–∫–∞–Ω–∞–ª–∞"
    else:
        return "–∫–∞–Ω–∞–ª–æ–≤"


def format_number(num_str: str) -> str:
    try:
        num_int = int(num_str)
        return f"{num_int:,}".replace(',', '.')
    except (ValueError, TypeError):
        return str(num_str)


async def get_country_info(code: str) -> str:
    if code == 'N/A': return ""
    try:
        async with httpx.AsyncClient(timeout=5) as client:
            response = await client.get(f"https://restcountries.com/v3.1/alpha/{code}")
            response.raise_for_status()
            data = response.json()[0]
            country_name = data['name']['common']
            flag_emoji = "".join([chr(0x1F1E6 + ord(char) - ord('A')) for char in code.upper()])
            return f"{flag_emoji} {country_name} ({code})"
    except Exception:
        return f"({code})"


def generate_metadata_content(data: dict) -> str:
    title = data.get('title', 'N/A')
    video_id = data.get('video_id', 'N/A')
    video_url = data.get('url', 'N/A')
    published_dt = datetime.fromisoformat(data['published_at'].replace('Z', '+00:00'))
    publish_date = published_dt.strftime("%Y-%m-%d %H:%M:%S")
    views = format_number(data.get('views', 'N/A'))
    category = data.get('category_name', 'N/A')
    tags = ", ".join(data.get('tags', []))
    description = data.get('description', '')
    content = (f"[TITLE]:       {title}\n[VIDEO ID]:    {video_id}\n[VIDEO URL]:   {video_url}\n"
               f"[PUBLISH DATE]: {publish_date}\n[VIEWS COUNT]: {views}\n[CATEGORY]:    {category}\n\n"
               f"[KEYWORDS (TAGS)]:\n{tags}\n\n[DESCRIPTION]:\n{description}\n")
    return content


# --- üöÄ –§–£–ù–ö–¶–ò–ò –°–ö–ê–ß–ò–í–ê–ù–ò–Ø (–Ø–î–†–û) ---

async def send_archive(message, file_paths, part_num, total_processed):
    """–°–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏–≤ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ —á–∞—Ç."""
    if not file_paths: return

    zip_filename = f"thumbnails_part_{part_num}.zip"
    try:
        with zipfile.ZipFile(zip_filename, 'w', compression=zipfile.ZIP_STORED) as zipf:
            for file_p in file_paths:
                zipf.write(file_p, arcname=os.path.basename(file_p))

        input_file = FSInputFile(zip_filename)
        caption = f"üìÅ –ê—Ä—Ö–∏–≤ ‚Ññ{part_num}\nüñº –ö–∞—Ä—Ç–∏–Ω–æ–∫: {len(file_paths)}\n(–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed})"
        await message.answer_document(input_file, caption=caption)
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—Ä—Ö–∏–≤–∞ ‚Ññ{part_num}: {e}")
    finally:
        if os.path.exists(zip_filename):
            try:
                os.remove(zip_filename)
            except:
                pass
        await asyncio.sleep(1)


async def batch_download_and_send(message: types.Message, channel_url: str, limit: int):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è HD –ø—Ä–µ–≤—å—é.
    """
    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞ (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ, –¥–æ–±–∞–≤–ª—è–µ–º /videos –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    clean_url = channel_url.split('?')[0].rstrip('/')
    if not clean_url.endswith('/videos') and not clean_url.endswith('/shorts'):
        target_url = clean_url + '/videos'
    else:
        target_url = clean_url

    status_msg = await message.answer(f"üîÑ –°–∫–∞–Ω–∏—Ä—É—é —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ (–ª–∏–º–∏—Ç: {limit})... –ü–æ–∏—Å–∫ HD –∫–∞—Ä—Ç–∏–Ω–æ–∫...")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ yt-dlp
    ydl_opts = {
        'extract_flat': True,
        'quiet': True,
        'playlistend': limit,
        'ignoreerrors': True,
        'no_warnings': True,
        'skip_download': True,
    }

    try:
        loop = asyncio.get_event_loop()
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = await loop.run_in_executor(None, lambda: ydl.extract_info(target_url, download=False))

        if 'entries' in info:
            entries = list(info['entries'])
        elif 'url' in info:
            entries = [info]
        else:
            entries = []

        total_found = len(entries)
        if total_found == 0:
            await status_msg.edit_text("‚ùå –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –í–æ–∑–º–æ–∂–Ω–æ, –∫–∞–Ω–∞–ª –ø—É—Å—Ç.")
            return

        await status_msg.edit_text(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {total_found}. –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ HD –ø—Ä–µ–≤—å—é...")

    except Exception as e:
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
        return

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—á–µ–∫
    MAX_ARCHIVE_SIZE = 45 * 1024 * 1024  # 45 –ú–ë
    MAX_FILES_COUNT = 500

    temp_dir = f"temp_thumbs_{message.from_user.id}"
    if os.path.exists(temp_dir): shutil.rmtree(temp_dir)
    os.makedirs(temp_dir)

    current_batch_files = []
    current_batch_size = 0
    part_num = 1
    processed_count = 0

    async with aiohttp.ClientSession() as session:
        for index, entry in enumerate(entries):
            video_id = entry.get('id')
            title = entry.get('title', 'video')
            if not video_id: continue

            # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å HD (maxresdefault)
            targets = [
                f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg",
                f"https://img.youtube.com/vi/{video_id}/hqdefault.jpg"
            ]

            img_data = None
            found_quality = False

            try:
                for url in targets:
                    async with session.get(url) as resp:
                        if resp.status == 200:
                            img_data = await resp.read()
                            found_quality = True
                            break

                if not found_quality or not img_data: continue

                file_size = len(img_data)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –ø–∞—á–∫–∏
                is_size_limit = (current_batch_size + file_size) > MAX_ARCHIVE_SIZE
                is_count_limit = len(current_batch_files) >= MAX_FILES_COUNT

                if (is_size_limit or is_count_limit) and current_batch_files:
                    await send_archive(message, current_batch_files, part_num, processed_count)

                    for f in current_batch_files:
                        try:
                            os.remove(f)
                        except:
                            pass

                    part_num += 1
                    current_batch_files = []
                    current_batch_size = 0

                    if index % 50 == 0:
                        try:
                            await status_msg.edit_text(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {index} –∏–∑ {total_found} (HD –∫–∞—á–µ—Å—Ç–≤–æ)...")
                        except:
                            pass

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                safe_title = "".join([c for c in title if c.isalpha() or c.isdigit() or c == ' ']).strip()
                safe_title = safe_title[:50]
                if not safe_title: safe_title = "img"

                filename = f"{safe_title}_{video_id}.jpg"
                filepath = os.path.join(temp_dir, filename)

                with open(filepath, 'wb') as f:
                    f.write(img_data)

                current_batch_files.append(filepath)
                current_batch_size += file_size
                processed_count += 1

            except Exception:
                continue

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
        if current_batch_files:
            await send_archive(message, current_batch_files, part_num, processed_count)

    if os.path.exists(temp_dir): shutil.rmtree(temp_dir)

    try:
        await status_msg.delete()
    except:
        pass

    await message.answer(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–∫–∞—á–∞–Ω–æ –≤ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ: {processed_count} —à—Ç.", parse_mode="HTML")


# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ---

@dp.message(Command("start"))
async def command_start_handler(message: types.Message, state: FSMContext):
    await state.clear()
    welcome_text = (
        "üôã <b>–ü—Ä–∏–≤–µ—Ç!</b>\n"
        "<b>–û—Ç–ø—Ä–∞–≤—å —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ/–∫–∞–Ω–∞–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.</b>\n\n"
        "<blockquote><b>üëá–ù–∏–∂–µ —Å–ø–∏—Å–æ–∫ –º–æ–∏—Ö –∫–æ–º–∞–Ω–¥</b></blockquote>\n"
        "<code>/analyze_video</code> ‚Äî (–∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ)\n"
        "<code>/analyze_channel</code> ‚Äî (–∞–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞)\n"
        "<code>/get_titles</code> ‚Äî (–≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è)\n"
        "<code>/google_trends</code> ‚Äî (—Ç—Ä–µ–Ω–¥-–∑–∞–ø—Ä–æ—Å—ã)\n"
        "<code>/excel</code> ‚Äî (—Å–±–æ—Ä –≤ Excel)\n"
        "<code>/download_prev</code> ‚Äî (—Å–∫–∞—á–∞—Ç—å –ø—Ä–µ–≤—å—é)\n"
        "<code>/cancel</code> ‚Äî (–æ—Ç–º–µ–Ω–∞)\n"
    )
    await message.answer(welcome_text, parse_mode="HTML", reply_markup=get_main_keyboard())
    msg_to_delete = await message.answer(".", reply_markup=ReplyKeyboardRemove())
    await msg_to_delete.delete()


@dp.message(Command("cancel"))
async def command_cancel_handler(message: types.Message, state: FSMContext):
    await state.clear()
    await message.answer("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.", reply_markup=get_main_keyboard())


# --- –ê–ù–ê–õ–ò–ó –í–ò–î–ï–û –ò –ö–ê–ù–ê–õ–û–í ---

async def run_video_analysis(message: types.Message, video_url: str, state: FSMContext):
    msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ...")
    data = await youtube_analyzer.analyze_video(video_url)

    if data.get("error"):
        await msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {data['error']}")
        await state.clear()
        return

    video_id = data['video_id']

    # --- 1. –ü–û–õ–£–ß–ê–ï–ú –î–ò–ó–õ–ê–ô–ö–ò (Return YouTube Dislike API) ---
    dislikes_count = 0
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"https://returnyoutubedislikeapi.com/votes?videoId={video_id}") as resp:
                if resp.status == 200:
                    ryd_data = await resp.json()
                    dislikes_count = ryd_data.get('dislikes', 0)
    except Exception:
        dislikes_count = 0  # –ï—Å–ª–∏ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    # ---------------------------------------------------------

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã
    try:
        dt = datetime.fromisoformat(data['published_at'].replace('Z', '+00:00'))
        formatted_date = dt.strftime("%d.%m.%Y %H:%M:%S")
    except:
        formatted_date = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    geo_info = await get_country_info(data.get('geo_code', 'N/A'))

    safe_title = html.escape(data['title'])
    safe_desc = html.escape(data.get('description', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'))

    # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
    if len(safe_desc) > 800:  # –õ–∏–º–∏—Ç –ø–æ–º–µ–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å —á–∞—Ç
        safe_desc = safe_desc[:800] + "... (—á–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ —Å—Å—ã–ª–∫–µ)"

    tags = data.get('tags', [])
    safe_tags = html.escape(", ".join(tags)) if tags else "–¢–µ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–≥–∏, –µ—Å–ª–∏ –∏—Ö –æ—á–µ–Ω—å –º–Ω–æ–≥–æ
    if len(safe_tags) > 500:
        safe_tags = safe_tags[:500] + "..."

    # –°–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    lines = [
        f"üé• <b><a href='{data['url']}'>{safe_title}</a></b>",
        f"‚îú –í—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: <code>{formatted_date}</code>",
        f"‚îú –ö–∞—Ç–µ–≥–æ—Ä–∏—è: <code>{data.get('category_name', 'N/A')}</code>"
    ]

    if geo_info:
        lines.append(f"‚îú –ì–ï–û: {geo_info}")

    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–∑–ª–∞–π–∫–∏ –≤ —Å—Ç—Ä–æ–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    lines.append(
        f"‚îî üëÄ: {format_number(data.get('views', 0))} ‚îÇ "
        f"üëç: {format_number(data.get('likes', 0))} ‚îÇ "
        f"üëé: {format_number(dislikes_count)} ‚îÇ "  # <--- –í–û–¢ –û–ù–ò
        f"üí¨: {format_number(data.get('comments', 0))}"
    )

    lines.append("")
    lines.append("üìù‚îÇ<b>–û–ø–∏—Å–∞–Ω–∏–µ</b>")
    lines.append(f"<blockquote>{safe_desc}</blockquote>")

    lines.append("")
    lines.append("üè∑‚îÇ<b>–¢–µ–≥–∏</b>")
    lines.append(f"<pre>{safe_tags}</pre>")

    markup = types.InlineKeyboardMarkup(inline_keyboard=[
        [types.InlineKeyboardButton(text="üì• –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ", callback_data=f"download_meta:{video_id}"),
         types.InlineKeyboardButton(text="üñºÔ∏è –ü—Ä–µ–≤—å—é", callback_data=f"download_thumb:{video_id}")]])

    await msg.delete()

    try:
        await message.answer("\n".join(lines), parse_mode="HTML", reply_markup=markup, disable_web_page_preview=True)
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã–≤–æ–¥–∞: {e}", reply_markup=markup)

    await state.clear()


async def run_channel_analysis(message: types.Message, channel_input: str, state: FSMContext):
    msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–∞–Ω–∞–ª...")
    data = await youtube_analyzer.analyze_channel(channel_input)
    if data.get("error"):
        await msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {data['error']}")
        await state.clear()
        return

    formatted_date = datetime.fromisoformat(data['published_at'].replace('Z', '+00:00')).strftime("%d.%m.%Y")
    lines = [f"üë§ <b>–ö–∞–Ω–∞–ª: <a href='{data['url']}'>{html.escape(data['title'])}</a></b>",
             f"‚îú –°–æ–∑–¥–∞–Ω: <code>{formatted_date}</code>",
             f"‚îú –í–∏–¥–µ–æ: <code>{format_number(data.get('video_count', 0))}</code>",
             f"‚îî –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: <code>{format_number(data.get('view_count', 0))}</code>"]

    buttons = []
    if 'avg_views' in data:
        lines.append("\n‚ù§Ô∏è <b>–ó–¥–æ—Ä–æ–≤—å–µ (–ø–æ 10 –≤–∏–¥–µ–æ):</b>")
        lines.append(f"‚îú –°—Ä. –ø—Ä–æ—Å–º–æ—Ç—Ä—ã: {format_number(data['avg_views'])}")
        lines.append(f"‚îî ER: {data['er']} %")
        buttons.append(
            types.InlineKeyboardButton(text="üìä –ì—Ä–∞—Ñ–∏–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", callback_data=f"show_graphs:{data['channel_id']}"))

    buttons.append(
        types.InlineKeyboardButton(text="üìÖ –¢–µ–ø–ª–æ–∫–∞—Ä—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π", callback_data=f"show_heatmap:{data['channel_id']}"))
    markup = types.InlineKeyboardMarkup(inline_keyboard=[buttons]) if buttons else None

    await msg.edit_text("\n".join(lines), parse_mode="HTML", reply_markup=markup, disable_web_page_preview=True)
    await state.clear()


# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î (–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï) ---

@dp.message(Command("analyze_video"))
async def cmd_analyze_video(message: types.Message, state: FSMContext):
    await message.answer("üîó –í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ:")
    await state.set_state(UserStates.waiting_for_video_link)


@dp.message(Command("analyze_channel"))
async def cmd_analyze_channel(message: types.Message, state: FSMContext):
    await message.answer("üîó –í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞–Ω–∞–ª:")
    await state.set_state(UserStates.waiting_for_channel_link)


@dp.message(Command("get_titles"))
async def cmd_get_titles(message: types.Message, state: FSMContext):
    await message.answer("üîó –°—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞–Ω–∞–ª –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏–π:")
    await state.set_state(UserStates.waiting_for_all_titles_link)


@dp.message(Command("google_trends"))
async def cmd_trends(message: types.Message, state: FSMContext):
    await message.answer("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤:")
    await state.set_state(UserStates.waiting_for_trends_query)


@dp.message(Command("excel"))
async def cmd_excel(message: types.Message, state: FSMContext):
    await message.answer("üìä –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è Excel —Ñ–∞–π–ª–∞:")
    await state.set_state(UserStates.waiting_for_niche_name)


# --- –õ–û–ì–ò–ö–ê –°–ö–ê–ß–ò–í–ê–ù–ò–Ø –ü–†–ï–í–¨–Æ (–û–ë–†–ê–ë–û–¢–ß–ò–ö–ò) ---

@dp.message(Command("download_prev"))
async def command_download_prev(message: types.Message, state: FSMContext):
    await message.answer("üì• <b>–°–∫–∞—á–∏–≤–∞–Ω–∏–µ HD –ø—Ä–µ–≤—å—é</b>\nüîó –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞–Ω–∞–ª:", parse_mode="HTML")
    await state.set_state(UserStates.waiting_for_thumb_channel)


@dp.message(UserStates.waiting_for_thumb_channel)
async def process_thumb_channel_step(message: types.Message, state: FSMContext):
    channel_input = message.text.strip()
    msg = await message.answer("üîç –ü—Ä–æ–≤–µ—Ä—è—é –∫–∞–Ω–∞–ª...")
    channel_data = await youtube_analyzer.analyze_channel(channel_input)

    if channel_data.get("error"):
        await msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {channel_data['error']}")
        return

    total_videos = int(channel_data.get('video_count', 0))
    if total_videos == 0:
        await msg.edit_text("‚ùå –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        await state.clear()
        return

    await state.update_data(thumb_channel=channel_input, max_videos=total_videos)
    await msg.delete()
    await message.answer(
        f"‚úÖ –ö–∞–Ω–∞–ª: <b>{html.escape(channel_data['title'])}</b>\nüìπ –í–∏–¥–µ–æ: {total_videos}\nüî¢ <b>–°–∫–æ–ª—å–∫–æ —Å–∫–∞—á–∞—Ç—å? (–æ—Ç 1 –¥–æ {total_videos})</b>",
        parse_mode="HTML")
    await state.set_state(UserStates.waiting_for_thumb_count)


@dp.message(UserStates.waiting_for_thumb_count)
async def process_thumb_count_step(message: types.Message, state: FSMContext):
    if not message.text.isdigit():
        await message.answer("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")
        return

    count = int(message.text)
    data = await state.get_data()
    channel_input = data.get('thumb_channel')
    max_videos = data.get('max_videos', 0)

    if count < 1: count = 1
    if count > max_videos:
        await message.answer(f"‚ö†Ô∏è –í—Å–µ–≥–æ {max_videos} –≤–∏–¥–µ–æ. –°–∫–∞—á–∏–≤–∞—é –≤—Å–µ.")
        count = max_videos

    await message.answer(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {count} –ø—Ä–µ–≤—å—é...")
    await state.clear()

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    await batch_download_and_send(message, channel_input, count)


# --- CALLBACKS ---

@dp.callback_query(F.data == "analyze_video")
async def cb_analyze_video(cb: types.CallbackQuery, state: FSMContext):
    await cb.message.answer("üîó –í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ:")
    await state.set_state(UserStates.waiting_for_video_link)
    await cb.answer()


@dp.callback_query(F.data == "analyze_channel")
async def cb_analyze_channel(cb: types.CallbackQuery, state: FSMContext):
    await cb.message.answer("üîó –í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞–Ω–∞–ª:")
    await state.set_state(UserStates.waiting_for_channel_link)
    await cb.answer()


@dp.callback_query(F.data == "get_all_titles")
async def cb_get_titles(cb: types.CallbackQuery, state: FSMContext):
    await cb.message.answer("üîó –°—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞–Ω–∞–ª:")
    await state.set_state(UserStates.waiting_for_all_titles_link)
    await cb.answer()


@dp.callback_query(F.data == "cmd_trends")
async def cb_trends(cb: types.CallbackQuery, state: FSMContext):
    await cb.message.answer("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:")
    await state.set_state(UserStates.waiting_for_trends_query)
    await cb.answer()


@dp.callback_query(F.data == "cmd_excel")
async def cb_excel(cb: types.CallbackQuery, state: FSMContext):
    await cb.message.answer("üìä –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞:")
    await state.set_state(UserStates.waiting_for_niche_name)
    await cb.answer()


@dp.callback_query(F.data.startswith("download_meta:"))
async def cb_dl_meta(cb: types.CallbackQuery):
    video_id = cb.data.split(":")[-1]
    await cb.answer("‚è≥ –ì–æ—Ç–æ–≤–ª—é —Ñ–∞–π–ª...")
    data = await youtube_analyzer.get_video_data_by_id(video_id)
    if not data.get("error"):
        content = generate_metadata_content(data)
        file = BufferedInputFile(content.encode('utf-8'), filename=f"{video_id}_meta.txt")
        await cb.message.answer_document(file)


@dp.callback_query(F.data.startswith("download_thumb:"))
async def cb_dl_thumb(cb: types.CallbackQuery):
    video_id = cb.data.split(":")[-1]
    await cb.answer("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é...")
    data = await youtube_analyzer.get_video_data_by_id(video_id)
    if data.get("thumbnail_url"):
        await cb.message.answer_photo(data['thumbnail_url'])


@dp.callback_query(F.data.startswith("show_graphs:"))
async def cb_show_graphs(cb: types.CallbackQuery):
    channel_id = cb.data.split(":")[-1]
    await cb.answer("üé® –†–∏—Å—É—é...")
    stats = await youtube_analyzer.get_recent_video_stats(channel_id)
    if not stats.get("error"):
        buf = create_activity_graphs(stats['views_list'], stats['likes_list'], stats['comments_list'])
        if buf: await cb.message.answer_photo(BufferedInputFile(buf.getvalue(), filename="graph.png"))


@dp.callback_query(F.data.startswith("show_heatmap:"))
async def cb_show_heatmap(cb: types.CallbackQuery):
    channel_id = cb.data.split(":")[-1]
    await cb.answer("üî• –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...")
    data = await youtube_analyzer.get_publication_heatmap_data(channel_id)
    if not data.get("error"):
        buf = create_heatmap_graph(data['grid'])
        if buf: await cb.message.answer_photo(BufferedInputFile(buf.getvalue(), filename="heatmap.png"),
                                              caption=data['report'], parse_mode="HTML")


# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –í–í–û–î–ê –î–ê–ù–ù–´–• (STATES) ---

@dp.message(UserStates.waiting_for_video_link)
async def process_video_link(message: types.Message, state: FSMContext):
    await run_video_analysis(message, message.text, state)


@dp.message(UserStates.waiting_for_channel_link)
async def process_channel_link(message: types.Message, state: FSMContext):
    await run_channel_analysis(message, message.text, state)


@dp.message(UserStates.waiting_for_all_titles_link)
async def process_all_titles(message: types.Message, state: FSMContext):
    msg = await message.answer("‚è≥ –°–æ–±–∏—Ä–∞—é –∑–∞–≥–æ–ª–æ–≤–∫–∏...")
    res = await youtube_analyzer.get_all_video_titles(message.text)
    if res.get("error"):
        await msg.edit_text(f"‚ùå {res['error']}")
        return

    titles = res['titles']
    if not titles:
        await msg.edit_text("–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        await state.clear()
        return

    text = f"–í—Å–µ–≥–æ: {len(titles)}\n\n" + "\n".join(titles)
    file = BufferedInputFile(text.encode('utf-8'), filename=f"titles.txt")
    await msg.delete()
    await message.answer_document(file, caption=f"‚úÖ –ì–æ—Ç–æ–≤–æ: {len(titles)}")
    await state.clear()


@dp.message(UserStates.waiting_for_trends_query)
async def process_trends(message: types.Message, state: FSMContext):
    msg = await message.answer("üìà –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...")
    res = await analyze_google_trends(message.text)
    if res.get("error"):
        await msg.edit_text(f"‚ùå {res['error']}")
        await state.clear()
        return

    photo = BufferedInputFile(res["image"].getvalue(), filename="trend.png")
    await msg.delete()
    await message.answer_photo(photo, caption=f"–¢–æ–ø —Å—Ç—Ä–∞–Ω–∞: {res['top_country']}")
    await state.clear()


@dp.message(UserStates.waiting_for_niche_name)
async def process_niche_name(message: types.Message, state: FSMContext):
    await state.update_data(niche_name=message.text, channels=[])
    await message.answer(f"‚úÖ –§–∞–π–ª '{message.text}' —Å–æ–∑–¥–∞–Ω. –û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ –∫–∞–Ω–∞–ª—ã.",
                         reply_markup=get_niche_analysis_keyboard())
    await state.set_state(UserStates.niche_analysis)


@dp.message(UserStates.niche_analysis, F.text == "üíæ –ì–æ—Ç–æ–≤–æ –∏ –°–∫–∞—á–∞—Ç—å")
async def finish_excel(message: types.Message, state: FSMContext):
    data = await state.get_data()
    channels = data.get('channels', [])
    if not channels:
        await message.answer("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.", reply_markup=get_main_keyboard())
        await state.clear()
        return

    msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é Excel...", reply_markup=ReplyKeyboardRemove())
    gen = ExcelGenerator(data['niche_name'])
    for ch in channels: gen.add_channel_data(ch['category'], ch)

    file = BufferedInputFile(gen.save_to_buffer().getvalue(), filename=f"{data['niche_name']}.xlsx")
    await msg.delete()
    await message.answer_document(file, caption="–í–∞—à –∞–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤.")
    await state.clear()


@dp.message(UserStates.niche_analysis)
async def process_niche_channel(message: types.Message, state: FSMContext):
    msg = await message.answer("üîç –ê–Ω–∞–ª–∏–∑...")
    data = await youtube_analyzer.analyze_channel(message.text)
    if data.get("error"):
        await msg.edit_text(f"‚ùå {data['error']}")
        return

    subs = int(data.get('subscriber_count', 0) or 0)
    cat = 'whales' if subs >= 100000 else 'small' if subs >= 1000 else 'tiny'

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞, –ø–æ–ª–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤ –≤–∞—à–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª–µ –±—ã–ª–∞ —Ç–∞–∫–∞—è –∂–µ)
    idea_7d = await youtube_analyzer.get_most_popular_video_in_range(data['channel_id'], 7)
    idea_14d = await youtube_analyzer.get_most_popular_video_in_range(data['channel_id'], 14)
    idea_30d = await youtube_analyzer.get_most_popular_video_in_range(data['channel_id'], 30)

    st_data = await state.get_data()
    channels = st_data.get('channels', [])
    channels.append({
        'category': cat, 'name': data['title'], 'url': data['url'], 'subs': subs,
        'views': int(data.get('view_count', 0)), 'idea_7d': idea_7d, 'idea_14d': idea_14d, 'idea_30d': idea_30d
    })
    await state.update_data(channels=channels)
    await msg.edit_text(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: {data['title']}. –í—Å–µ–≥–æ: {len(channels)}.", parse_mode="HTML")


# --- –£–ú–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö (–í –°–ê–ú–û–ú –ö–û–ù–¶–ï!) ---
@dp.message(F.text, StateFilter(None))
async def auto_detect_handler(message: types.Message, state: FSMContext):
    text = message.text.strip()
    if youtube_analyzer._extract_video_id(text):
        await run_video_analysis(message, text, state)
    elif youtube_analyzer._extract_channel_info(text):
        await run_channel_analysis(message, text, state)
    else:
        await message.answer("–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª —Å—Å—ã–ª–∫—É. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é.")


# --- –ó–ê–ü–£–°–ö ---
async def start_web_server():
    port = int(os.getenv("PORT", 8000))
    app = web.Application()
    app.router.add_get('/', lambda r: web.Response(text="Alive"))
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', port)
    await site.start()
    logging.info(f"üåê Server on {port}")


async def main():
    logging.info("üöÄ Bot started")
    await start_web_server()
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())